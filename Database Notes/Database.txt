Transaction -> A series of action to perform a specific task

R(old bal 1st acct)
w(newbie 1st acct)
R(old bal 2nd acct)
w(new bal 2nd acct)
To transfer monry from one to another

Transactsions must have the following characteristics

A) Atomic-> it appears to the user to be a simple task which either all completed or not done at all

B) Consistency -> the transaction must leave the DB in a "consistent" (correct given our intentions) state.

C) Isolation -> to the user, each transation is seperate entity not affected by other users transactions

D) Durable -> if the system crases, the transactions must still be on the system.

E) Transaction Sechedule -> is the list of actions for a transaction. It can show many transactions concurrently progress. Allows DBMS to be aware and to manage concurrency issue.

Let A = an Object

R(A) -> read A
w(A) -> write A
S(A) -> request a shared lock on object A
X(A) -> request an exclusive lock on A

The end of each "Abort" or "commit"

Lock-> when we make Object A Not available
	Lock Granularity-> how big of a lock must we do?
		1)The field
		2)The Record
		3)The block or page ] Most common
		4)Whole file or DB
		
Locking Scheme
	Share Lock-> other transactions can read our info
	Exclusive lock-> No one else can access
	
Lock Duration-> some sort of timing for a lock

DeadLock-> When a transaction has a Lock on A, another needs it to continue their work. Perhaps they have a lock on B, and 1st one is waiting on it.

Timestamp-> could be an time d date, but could just be a number.

Locking Protocol-> a set of rules for locking objects to prevent anomolies.

Types of anomolies
A) Write Read (WR) Conflict-> where 1 transaction reads data modified by another transaction which has not commited -> Dirty Read

B) Read Write(RW) conflict-> one transaction has read an object; another transaction concurrently writes the object. WHen the First transactions reads the object again, the data is different.

WW Conflict -> When 2 transactions read the record and each write it back. Both are based on original data; DB will be incorrect.

Lock Management:
Lock manager manages a lock able(a hash table with the objects identifier as its key) + will contain info about the locks

#of transactions holding a lock on an object
-the type of lock(SorX)
-a pointer to a Q of lock requests

When a lock is requested, the LM goes to the table to look for that object.
If it is not in the table, it is entered into the table and appropriate information is added. -> Lock Granted

-If it has a shared lock on it and a shared lock is requested, it checks the Q to see if any other request is in there for htis object.
-> If the Q does not have another request, shared lock is granted.
-> if there is some other lock request in the Q, the first must be an exclusive lock request.-> Preventing this request from starving -> unlikely to be fulfilled in a reasonable time. SO EnQ this lock request
If an exclusive lock is requested - if the object is currently locked, we EnQ this request - wait until the locks are released
If a shared lock needs to be upgraded 
	-if no other transaction is sharing the lock, the upgrade is granted.
If another is sharing it, this exclusive lock is pushed - put into the first position in the Q.

Strict 2PL

2 Phase Locking Protocol
-----------------------------
	for a transaction, 2 phases:
		Growing Phase-> All lock requests are granted and held until we get commit or abort
		Shrinking Phase-> When all locks are released upon commit or abort
		"Non-strict" - Some locks will be released before commit/abort
		once 1 lock is released, it can't ask for another lock
=============================
Lock Performance
Thrashing-> when we have lots of transactions active, system may block new transactions as the chances of them blocking each other grows.

Some Answers:
	1) Have a max# of transactions allowed at any given time
	2)Use a lower level of lcoking procedure granularity
	3)Reduce time allowed for blocks
	4) Speed up transactions -> reqrite queries to be more efficient.
	5) Could be handled by programming
	6) Copy some to another loaction to another site and do work there
	
Methods of Handling deadlock
	1) Deadlock Prevention-> use a timestamp that keeps track of the order of transactions beginning on system.
		A) IF T2 requests a lock while T1 holds the lock then:
			i)wait-die: If T2 has a higher priority, it is allowed to wait, otherwise its aborted(t2 is the victim).
			ii)wound-die: If T2 has a higher priority, T1 is aborted, otherwise T2 waits (T1 is the victim).
			
	2) Deadlock detection - idea is that deadlocks are actually quite rare, so we create a "waits-for" graph is maintained and used to detect cycles.
		Transactions are nodes on the graph, arcs between nodes shows one is waiting for hte other. T1T2 means T1 is waiting for T2.Lock Manager adds arcs as requests are made and deletes them when the lock request is granted.
		
Recovery Services
	Still maintain->A - Atomic
			C - Consistency
			I - Isolation
			D - Durability
	A) Backup or Saved copy - the DB at a specific point of time
	B)Journaling - The Dbms keeps a transaction log which has every record changed before and after. Has a Start and finished with an Abort or commit) Write Ahead log - WAL
		
	C) Forward Recovery -> Copy Backup File to replace the Damaged DB, then the DBMS goes through and does each action from the log in order until it reaches the point where it crashed. Any transation not commited or Aborted is backed out using the log. Sometimes, many changes might have to the same record. Some systems will sort the log and just do the last modification.
	D) Backward Recovery - In a case where only some transaction caused the problem - only update the system appropriatedly (ie undo uncommited transactions)
	
	E) Differential Files - All changes to the DB are stored in a different file, often on a permanent disk somewhere else) and all updates are actually there. (generally faster unless there are many, many transactions. THis file is used for all later requests and only if not found is actual DB used.
	F) Check Point -> Every so often(every 15 min or 1 hour) the system flushes changes to the actual DB THe entire system freezes while it updates. 
	G) If all else fails we back out of each transaction manually.
	
===============================================

Aries - 3 Phrase recovery
------------------------
Algorithm
Analysis - THe DB identifies the last correct point and active and dirty transaction
Redo - Redoes all that were commited
undo - undoes those that were not commited

Store data in our files:
1)sorted by key field(s)
2) Heap Files -> any old in which it comes from
3) Hashed files

Heap File -> data put in no particular order
Sorted file -> ordered by key fields
Hached file -> data is located by using a hash) puts them in a specific bucket

Cost Model
C- Average time to process a record generally a field comparison
H- THe time to use the hash formula
Notation:
B = # of data pages
R = # of records per page
D = Average time to read/write a page(to/from disk)
Operations to compare

Scan-> fetch all records in a file
Search with equality->fetch all records which satisfy an "=" criteria
Search with range selection

Heap File
------------------------------
Scan->every page will be read
	Cost = B(D+RC)
Search with equality Selection
	COst = 1/2(B(D+RC)
Search with Not a key field
	Cost = B(D+RC)
Search with Range slection -> essentially a scan
	Cost = B(D+RC)

Insert
2B+C
Delete
Cost = Search + C + D
